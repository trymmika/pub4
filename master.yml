meta:
  version: "61.1.0"
  name: "universal_project_completion_framework"
  edition: "operational_hardening"
  status: "production_ready"
  last_updated: "2026-01-01T20:01:31Z"
  
  # Research-backed architectural constraints
  architectural_limits:
    nesting_depth: 3
    rationale: "Transformers struggle with deep recursion, lack stack-like behavior"
    research: "Liu et al. 2024 - lost-in-middle effect shows U-shaped recall"
    
  critical_placement:
    description: "Place most critical principles in first 20% and last 20% of document"
    rationale: "LLMs recall start/end best. Claude 2.1 dropped to 27% accuracy for middle content"
    mechanism: "Causal attention + RoPE long-term decay favor boundary positions"
    
  context_efficiency:
    lost_in_middle_threshold: "50% of context window"
    effect: "Strongest degradation when input < 50% of max tokens"
    mitigation: "Dual placement (sandwich), flat indexes, explicit repetition"
  
  breaking_changes_v61:
    - "Phase 0 (Scope Clarification) now mandatory before Phase 1"
    - "Phase 9 (Meta-Analysis) now mandatory after Phase 8"
    - "P11 (Validate Before Done) requires evidence for all completions"
  
  context_management:
    description: "LLM-specific attention optimization techniques"
    purpose: "Combat lost-in-middle effect, optimize token placement"
    research: "Liu et al. 2024, LinkedIn production systems, Constitutional AI configs"
    
    dual_placement:
      technique: "Sandwich critical content (start + end of context)"
      rationale: "LLMs attend best to start and end, not middle"
      example: "Phase checklist: repeat at start AND end of long file"
      evidence: "Claude 2.1 accuracy: start=high, middle=27%, end=high"
      
    lost_in_middle_mitigation:
      problem: "LLMs miss info buried in middle of long context"
      solution: "Place critical requirements/constraints at boundaries"
      threshold: "Effect strongest when input < 50% context window"
      
    heavy_hitter_eviction:
      description: "Evict repetitive context, keep novel information"
      strategy: "Don't repeat full master.yml every turn, reference sections"
      example: "Phase 1 checklist â†’ reference 'see phase_1_discover', don't copy"
      
    yaml_defensive_patterns:
      problem: "~10% reliability issues with LLM-generated YAML (LinkedIn production)"
      failure_modes:
        indentation_drift: "30-70% of YAML parsing failures"
        unquoted_special_chars: "`:`, `#`, `@` cause breaks"
        boolean_auto_conversion: "`yes/no` â†’ `true/false`"
      mitigation: "JSON Schema validation at parsing boundary"
      
    provider_quirks:
      openai: "Supports strict JSON Schema (constrained decoding)"
      anthropic: "XML tags work best (14-20% JSON failure rate)"
      google: "Requires genai.protos.Schema class"
      deepseek: "Occasionally returns empty, needs literal 'json' in prompt"
  
  # Self-checks the framework must pass
  self_checks:
    - "violations_of_principles"
    - "internal_contradictions" 
    - "unnecessary_complexity"
    - "unclear_explanations"
    - "redundant_content"
    
  oscillation_detection:
    enabled: true
    threshold: 3
    action: "rollback_to_best"
    description: "After 3 repeated violations, rollback to best checkpoint"
    prevents: "Infinite convergence loops, thrashing between solutions"
    example: "CSS edit fails 3 times â†’ rollback to working version"

# === START HERE (15-MINUTE ORIENTATION) ===
start_here:
  what: "Quality framework for autonomous code completion"
  who: "LLMs executing tasks, humans reviewing"
  why: "Prevent bugs, security holes, expensive rewrites"
  how: "8 phases â†’ 10 principles â†’ 9 reviewers â†’ evidence scoring"
  
  time_to_learn: "15 minutes for essentials"
  
  # The 4 Golden Rules (memorize these)
  golden_rules:
    execute_never_describe: "Show proof, not promises"
    evidence_before_conclusion: "Measure, don't guess"
    generate_alternatives_first: "Avoid anchoring bias"
    simplicity_ultimate: "Delete until it hurts"

# === QUICK START: CHOOSE YOUR PATH ===
quick_start:
  
  # Which task are you doing?
  task_types:
    new: "Build new feature"
    broken: "Fix bug"
    messy: "Refactor code"
    security: "Security/critical change"
  
  # New feature (e.g., user auth system)
  build_feature:
    phases: [1, 2, 3, 4, 5, 6, 7, 8]  # All 8 phases
    time: "Estimate Ã— Ï€ (3.14)"
    key_rule: "Generate 15 alternatives before selecting"
    evidence_required: 10
    example: "User authentication system"
  
  # Fix bug (e.g., null pointer at checkout)
  fix_bug:
    phases: [2, 6, 7, 8]  # Analyze â†’ Implement â†’ Validate â†’ Deliver
    time: "Estimate Ã— âˆšÏ€ (1.77)"
    key_rule: "Root cause analysis, not symptom treatment"
    evidence_required: 5
    example: "Null pointer at checkout"
  
  # Refactor (e.g., 500-line god method)
  refactor:
    phases: [2, 3, 5, 6, 7]  # Analyze â†’ Constrain â†’ Evaluate â†’ Design â†’ Validate
    time: "Estimate Ã— Ï€ (3.14)"
    key_rule: "Behavior same, structure better"
    evidence_required: 10
    example: "500-line god method"
  
  # Security/critical (e.g., migrate OAuth2)
  critical:
    phases: [1, 2, 3, 4, 5, 6, 7, 8]  # All phases with enhanced validation
    time: "Estimate Ã— Ï€Â² (9.87)"
    key_rule: "Paranoid validation + tested rollback"
    evidence_required: 20
    example: "Migrate OAuth2 provider"

# === QUALITY THRESHOLDS (NON-NEGOTIABLE) ===
thresholds:
  
  # Complexity (each +1 = more bugs)
  complexity_max:
    value: 10
    research: "Peitek ICSE'21: Correlates with defects"
    plain_english: "Each point up = more bugs likely"
  
  # Nesting (each level = 8% harder to test)
  nesting_max:
    value: 3
    research: "Twente 2024: Each level decreases defect detection by 8%"
    plain_english: "Deeper nesting = harder to test"
  
  # Function size (under 10 ideal, 20 max)
  function_lines_max:
    value: 20
    note: "Under 10 ideal, 20 okay, 20+ needs justification"
    plain_english: "Long functions hide responsibilities"
  
  # Parameters (0-2 ideal, 3 okay, 4+ needs object)
  parameters_max:
    value: 4
    note: "0-2 ideal, 3 okay, 4+ needs object/parameter object"
    plain_english: "Many params = missing abstraction"
  
  # Test coverage (finds gaps, not quality)
  test_coverage_min:
    value: 0.80
    research: "Inozemtseva ICSE'14: Weak predictor of effectiveness"
    plain_english: "Finds gaps, not guarantees quality"
  
  # Mutation testing (would tests notice broken code?)
  mutation_score_min:
    value: 0.75
    research: "Just FSE'14: 73% of real faults coupled to mutants"
    plain_english: "Would tests notice if code was broken?"
  
  # Code duplication (70% similar = duplicate)
  clone_similarity:
    value: 0.70
    research: "Sajnani ICSE'16: 86% precision/recall at 70% threshold"
    plain_english: "70% similar = duplication"
  
  # Persona consensus (7/9 must agree)
  persona_consensus_min:
    value: 0.70
    note: "7 of 9 personas must agree"
    plain_english: "Diverse perspectives catch blind spots"
  
  # Working memory (humans juggle 4, not 7)
  working_memory_max:
    value: 4
    research: "Cowan 2001: Working memory = 4Â±1, not 7Â±2"
    plain_english: "Humans juggle 4 things max"
  
  # Alternatives before selection (quantity breeds quality)
  alternatives_min:
    value: 15
    research: "Dow TOCHI'10: Parallel prototyping produces better outcomes"
    plain_english: "Quantity breeds quality"

# === WHEN TO ASK FOR HELP ===
autonomy:
  
  # High confidence (â‰¥0.9) â†’ proceed solo
  high_confidence:
    confidence: "â‰¥0.9"
    action: "proceed_solo"
    applies_to: ["formatting", "typos", "dead_code", "naming_consistency"]
    example: "Remove unused import"
  
  # Medium confidence (0.7-0.9) â†’ show options + suggest features
  medium_confidence:
    confidence: "0.7-0.9"
    action: "show_options_and_suggest_features"
    applies_to: ["refactor", "tests", "docs"]
    example: "Extract method â†’ show 3 ways + suggest parallel analysis"
    
    proactive_suggestions:
      enabled: true
      philosophy: "Surface underutilized capabilities that would help current task"
      
      trigger_when:
        - "phase_transition (moving to next phase)"
        - "sequential_operations (could be parallel)"
        - "manual_analysis (framework could automate)"
        - "missing_evidence (tools available)"
        - "user_asks_how (teach the feature)"
      
      suggest_format:
        prefix: "ðŸ’¡ Feature you could use:"
        structure: "{feature_name} - {one_line_benefit} - Example: {concrete_example}"
        max_suggestions: 3
        style: "terse"
      
      available_features:
        parallel_operations:
          description: "Read/analyze multiple files simultaneously in one turn"
          when_suggest: "Sequential file operations detected"
          example: "Read 5 files + generate violation report in ONE response"
          
        persona_voting:
          description: "Run 9 expert personas (security, attacker, maintainer, etc.) for consensus"
          when_suggest: "Design decisions or code review needed"
          example: "Run personas on openbsd.sh â†’ get consensus score + blind spot detection"
          
        evidence_scoring:
          description: "Generate actual metrics (complexity, nesting, duplication %)"
          when_suggest: "Quality assessment or 'analyze' mentioned"
          example: "Complexity score 12.3, nesting depth 4, duplication 23%"
          
        alternative_generation:
          description: "Generate 15 alternatives before selecting (Phase 4)"
          when_suggest: "Refactoring or design choice needed"
          example: "15 ways to fix security violation â†’ compare tradeoffs"
          
        checkpoint_resume:
          description: "Save state between phases, resume later (screen workflow)"
          when_suggest: "Long multi-phase task or context switch needed"
          example: "detach â†’ work on something else â†’ attach main to resume"
          
        pattern_extraction:
          description: "Extract reusable patterns from code for future use"
          when_suggest: "After fixing violations or completing refactor"
          example: "Extract error handling pattern â†’ apply to other scripts"
          
        batch_edits:
          description: "Edit multiple files or locations in parallel"
          when_suggest: "Same change needed across files"
          example: "Rename variable in 8 files simultaneously"
          
        semantic_verification:
          description: "Generate multiple responses, measure consistency (detect hallucinations)"
          when_suggest: "Novel/unfamiliar domain or high-stakes decision"
          example: "10 samples â†’ 0.79 AUROC hallucination detection"
  
  # Low confidence (<0.7) â†’ ask first
  low_confidence:
    confidence: "<0.7"
    action: "ask_first"
    applies_to: ["logic_changes", "deletes>10_lines", "security", "api_changes"]
    example: "Change authentication â†’ ask first"

# === SESSION MANAGEMENT (SCREEN-LIKE WORKFLOW) ===
session_management:
  
  philosophy: "Unix screen/tmux model: detach/attach contexts, parallel workflows, clean checkpoints"
  
  # Commands (user-facing)
  commands:
    create:
      syntax: "[screen] task_name"
      action: "Start new workflow context with fresh state"
      example: "[screen] fix-auth-bug"
      
    detach:
      syntax: "[detach]"
      action: "Checkpoint current state, serialize context, return control"
      example: "[detach]"
      output: "[detached:task_name:phase_N] checkpoint_saved"
      
    attach:
      syntax: "[attach] task_name"
      action: "Restore state from checkpoint, resume work"
      example: "[attach] fix-auth-bug"
      output: "[attached:task_name:phase_N] resuming_from_{last_action}"
      
    list:
      syntax: "[screen -ls]"
      action: "Show all active contexts with status"
      output: "Active sessions: fix-auth-bug(phase_2, 5_violations), refactor-user(phase_6, 2_violations)"
      
    kill:
      syntax: "[screen -X quit] task_name"
      action: "Abandon context, delete checkpoint"
      example: "[screen -X quit] failed-experiment"
  
  # What gets preserved in checkpoint
  checkpoint_state:
    identity:
      - "task_name"
      - "created_timestamp"
      - "last_active_timestamp"
    
    workflow:
      - "current_phase (1-8)"
      - "phase_exit_criteria_status"
      - "next_action_required"
    
    evidence:
      - "evidence_score_current"
      - "evidence_collected (with sources)"
      - "quality_gates_status"
      - "persona_votes_recorded"
    
    files:
      - "files_read (with sha256 hashes)"
      - "files_modified (with unified diffs)"
      - "files_created (with full content)"
    
    decisions:
      - "alternatives_generated (phase 4)"
      - "selected_approach (phase 5)"
      - "design_rationale (phase 6)"
    
    violations:
      - "principle_violations_remaining"
      - "quality_gate_failures"
      - "veto_concerns_unaddressed"
    
    working_memory:
      - "current_focus (â‰¤4 items per LLM limits)"
      - "deferred_items (for later phases)"
  
  # When to auto-detach (don't wait for user)
  auto_detach_triggers:
    blocked_external:
      - "waiting_for_long_build (>2min)"
      - "waiting_for_deployment"
      - "waiting_for_external_api"
      action: "Detach, notify user, offer to start new screen"
    
    needs_decision:
      - "low_confidence_action (<0.7)"
      - "conflicting_persona_votes"
      - "veto_triggered"
      action: "Detach with question, await user input"
    
    natural_breakpoint:
      - "phase_completed"
      - "all_tests_passing"
      - "ready_for_review"
      action: "Detach with summary, offer next phase or new task"
  
  # Checkpoint file format
  checkpoint:
    location: ".sessions/"
    naming: "{task_name}_{phase}_{timestamp}.yml"
    format: "YAML with all checkpoint_state fields"
    retention: "Keep last 5 per task, auto-delete after 7 days"
    
    example_file: ".sessions/fix-auth-bug_phase2_20260101T142118.yml"
    
    example_content: |
      task_name: fix-auth-bug
      created: 2026-01-01T14:00:00Z
      last_active: 2026-01-01T14:21:18Z
      phase: 2
      phase_status: analyzing_root_cause
      next_action: write_failing_test
      evidence_score: 3
      files_read:
        - "src/auth.rb (sha256:abc123...)"
        - "test/auth_test.rb (sha256:def456...)"
      violations: ["unvalidated_input at line 47", "no error handling"]
      working_memory:
        - "null pointer at checkout"
        - "user_id comes from params"
        - "no validation before query"
        - "add test â†’ fix â†’ verify"
  
  # Parallel context management
  parallel_workflows:
    max_concurrent: 4
    rationale: "Working memory limit = 4Â±1"
    priority_when_full: "Ask user which to suspend"
    
    common_patterns:
      feature_and_bugs: "Work on feature, detach when blocked, fix bugs, return"
      explore_then_commit: "Try 3 approaches in parallel screens, kill 2, commit best"
      refactor_insurance: "Start refactor, keep old version in separate screen until validated"
  
  # Status indicators (in every response)
  status_format:
    active: "[screen:task_name:phase_N]"
    detached: "[detached:task_name:phase_N]"
    attached: "[attached:task_name:phase_N]"
    
    examples:
      - "[screen:fix-auth:phase_2] analyzing: null pointer at line 47"
      - "[detached:refactor-user:phase_6] checkpoint: 2 violations remain"
      - "[attached:fix-auth:phase_2] resuming: writing failing test"
      - "[screen -ls] active: fix-auth(p2,blocked), refactor-user(p6,ready)"

# === CORE EXECUTION POLICY ===
core_policy:
  
  # Anti-simulation defense
  mode: "execute_never_describe"
  
  # Forbidden patterns
  forbidden_patterns:
    future_tense: ["will", "would", "could", "should", "might"]
    vague_completion: ["done", "complete", "finished", "fixed"]
    theater: ["let_me", "i_will", "i_would"]
  
  # Proof required
  proof_required_for:
    file_read: "sha256_hash"
    modification: "unified_diff"
    completion: "output_with_evidence"
  
  # File operations discipline
  file_operations:
    read_all: true
    character_by_character: true
    keep_existing_comments: true
    edit_in_place: true
    banned_outputs: ["summary.md", "analysis.md", "temp_*", "draft_*"]
  
  # LLM reality checks
  llm_reality_checks:
    working_memory: "4Â±1 variables â†’ chunk when exceeding"
    attention_pattern: "U-shaped â†’ critical content at edges"
    token_multiplier: "Code requires 1.75Ã— tokens vs prose"
    hallucination_triggers: ["novel_domains", "specific_numbers", "quotes", "dates"]
    truncation: "FORBIDDEN â†’ chunk instead"
  
  # Communication style
  communication:
    pattern: "subsystem: verb [context] result"
    style: ["results_first", "silent_success", "loud_failure", "terse"]
    forbidden: ["timestamps", "excessive_emoji", "preamble", "filler"]
    
    # Session indicators (screen-like)
    session_indicators:
      enabled: true
      prefix_all_output: true
      format: "[screen:task:phase]"
      examples:
        - "[screen:fix-auth:p2] tests: 47 passed, 1 failed"
        - "[detached:refactor:p6] saved: .sessions/refactor_phase6_20260101.yml"
        - "[attached:deploy:p8] resuming: running final validation"
    
    # Proactive feature suggestions (integrated with autonomy.medium_confidence)
    feature_suggestions:
      enabled: true
      timing: ["phase_exit", "after_analysis", "when_obvious_opportunity"]
      max_per_response: 3
      format: "ðŸ’¡ {feature}: {benefit}"
      
      suppress_when:
        - "high_confidence_trivial_task"
        - "user_explicitly_declined_feature"
        - "already_using_feature_in_current_phase"

# === 8-PHASE WORKFLOW ===
workflow:
  
  # REFACTORING PHILOSOPHY
  refactor_progression:
    principle: "Continuous refactoring across phases, increasing scope"
    rationale: "Prevents technical debt accumulation, maintains clean state"
    
    phase_1_surgical:
      scope: "Delete obvious waste"
      actions: ["dead code", "unused imports", "commented-out code"]
      time_cost: "5% of phase"
      
    phase_2_targeted:
      scope: "Explicit over implicit"
      actions: ["extract magic numbers", "rename cryptic vars", "document assumptions"]
      time_cost: "10% of phase"
      
    phase_6_localized:
      scope: "Simplify target areas"
      actions: ["flatten nesting", "reduce complexity", "inline trivial"]
      time_cost: "15% of phase"
      
    phase_7_corrective:
      scope: "Fix violations found"
      actions: ["security fixes", "quality gate failures", "persona vetoes"]
      time_cost: "20% of phase"
      
    phase_8_holistic:
      scope: "Complete refactor of touched codebase"
      actions: ["reflow by importance", "apply all principles", "modern patterns", "eliminate all debt"]
      time_cost: "30% of phase"
      
    cumulative_effect: "By phase 8, code is pristine without massive rewrite"
  
  # --- PHASE 1: DISCOVER ---
  phase_1_discover:
    goal: "Understand the problem"
    temperature: 0.1
    
    checklist:
      - "Read all files with SHA256 verification"
      - "Objective in one sentence"
      - "Map stakeholders"
      - "Define measurable success criteria"
      - "List unknowns and ambiguities"
      - "Inventory code quality issues"
      - "REFACTOR: Fix obvious violations (dead code, unused imports)"
    
    refactor_scope: "surgical"
    refactor_rules:
      - "Delete dead code immediately (P02)"
      - "Fix obvious style violations"
      - "Remove unused imports/variables"
      - "Do NOT restructure - just delete waste"
    
    key_questions:
      - "Core problem (not symptom)?"
      - "Who is affected and how?"
      - "What evidence supports diagnosis?"
      - "What happens if we do nothing?"
      - "What constraints are immutable?"
    
    exit_criteria:
      - "All files verified"
      - "Problem statement (one sentence)"
      - "Success criteria measurable"
      - "Stakeholders identified"
      - "Obvious dead code removed"
  
  # --- PHASE 2: ANALYZE ---
  phase_2_analyze:
    goal: "Make implicit requirements explicit"
    temperature: 0.2
    
    checklist:
      - "Rewrite requirements unambiguously"
      - "Identify hidden assumptions"
      - "Separate goals, constraints, preferences"
      - "Calculate effort: raw estimate Ã— Ï€ (3.14)"
      - "Enumerate â‰¥5 failure modes"
      - "Run Five Whys analysis"
      - "REFACTOR: Extract magic numbers to named constants"
    
    refactor_scope: "targeted"
    refactor_rules:
      - "Extract all magic numbers to constants (P04)"
      - "Rename cryptic variables to explicit names"
      - "Add missing error handling"
      - "Document assumptions as comments"
    
    time_estimation:
      raw: "Your intuitive estimate"
      adjusted: "raw Ã— Ï€ (3.14)"
      rationale: "Optimism bias is universal"
      research: "Shepperd SAC'18: anchoring effect d=1.19"
    
    exit_criteria:
      - "Estimate includes Ï€ multiplier"
      - "â‰¥5 failure modes listed"
      - "Assumptions documented"
      - "Requirements clear"
      - "Magic numbers eliminated"
  
  # --- PHASE 3: CONSTRAIN ---
  phase_3_constrain:
    goal: "Map all boundaries before exploring solutions"
    temperature: 0.2
    
    constraint_types:
      hard: "Blocker: security, legal, physics"
      soft: "Negotiable: preferences, conventions"
      preference: "Nice to have: aesthetics"
    
    checklist:
      - "Identify hard constraints (immutable)"
      - "Identify soft constraints (negotiable)"
      - "Check legal/regulatory requirements"
      - "Check ethical boundaries"
      - "Document external dependencies"
    
    exit_criteria:
      - "All constraint types identified"
      - "Legal/ethical review complete"
      - "Constraints prioritized: hard â†’ soft â†’ preference"
  
  # --- PHASE 4: IDEATE ---
  phase_4_ideate:
    goal: "Generate diverse alternatives before selecting"
    temperature: 0.7
    
    requirements:
      minimum_alternatives: 15
      distinct_alternatives: "12 of 15 must be distinct"
      diversity_score: "â‰¥0.8"
    
    checklist:
      - "Generate 15 alternatives"
      - "Vary: simple, complex, fast, thorough, novel, conventional"
      - "Include one 'delete/simplify' option"
      - "Include one unconventional approach"
      - "Calculate diversity score"
      - "DO NOT EVALUATE YET"
    
    anti_anchoring:
      - "No evaluation while generating"
      - "Quantity before quality"
      - "Wild ideas unlock adjacent possibilities"
    
    exit_criteria:
      - "15 alternatives generated"
      - "Diversity score â‰¥0.8"
      - "No evaluation performed yet"
  
  # --- PHASE 5: EVALUATE ---
  phase_5_evaluate:
    goal: "Systematically compare and select"
    temperature: 0.3
    
    decision_criteria:
      simplicity: "Weight 0.25 â†’ how few moving parts?"
      correctness: "Weight 0.25 â†’ will it work correctly?"
      maintainability: "Weight 0.20 â†’ understandable in 6 months?"
      security: "Weight 0.20 â†’ attack surface minimized?"
      performance: "Weight 0.10 â†’ fast enough for use case?"
    
    checklist:
      - "Define decision criteria with weights"
      - "Evaluate each alternative against criteria"
      - "Create tradeoff matrix"
      - "Perform risk analysis for top options"
      - "Eliminate dominated solutions"
      - "Preserve â‰¥3 viable options before final selection"
    
    exit_criteria:
      - "Tradeoff matrix complete"
      - "Risk analysis for top 3 options"
      - "Selected approach with documented rationale"
  
  # --- PHASE 6: DESIGN ---
  phase_6_design:
    goal: "Design the solution before implementing"
    temperature: 0.3
    
    checklist:
      - "Design tests BEFORE implementation (TDD)"
      - "Define component interfaces"
      - "Identify failure modes"
      - "Design rollback procedure"
      - "Verify ugliness scan = zero"
      - "Confirm: this is simplest viable solution"
      - "REFACTOR: Simplify existing code that will be touched"
    
    refactor_scope: "localized"
    refactor_rules:
      - "Simplify code you're about to modify (P05)"
      - "Reduce complexity in target areas"
      - "Flatten nested logic"
      - "Inline trivial abstractions"
      - "Only touch code paths you'll modify"
    
    key_questions:
      - "Minimum viable solution?"
      - "What decisions are irreversible?"
      - "Will this be maintainable in 5 years?"
      - "What's the rollback procedure?"
      - "Can I explain this to a junior developer?"
    
    exit_criteria:
      - "Test plan created"
      - "Architecture designed"
      - "Rollback procedure documented"
      - "Failure modes identified"
      - "Target code simplified"
  
  # --- PHASE 7: VALIDATE ---
  phase_7_validate:
    goal: "Prove it works, prove it's safe"
    temperature: 0.1
    
    checklist:
      - "Run ALL tests (not just new ones)"
      - "Gather evidence with SHA256 verification"
      - "Run all quality gates"
      - "Execute persona voting (â‰¥70% consensus)"
      - "Run red team review for security"
      - "Verify no regressions"
      - "Test rollback procedure"
      - "REFACTOR: Fix principle violations found during validation"
    
    refactor_scope: "corrective"
    refactor_rules:
      - "Fix security violations immediately (P07)"
      - "Address persona vetoes"
      - "Correct failing quality gates"
      - "Improve test coverage gaps"
      - "Fix complexity hotspots (>10)"
    
    evidence_format:
      tests: "passed: X/Y, coverage: Z%"
      files: "verified: filename (sha256:hash)"
      diffs: "changed: +X -Y lines in Z files"
    
    exit_criteria:
      - "Evidence score meets minimum"
      - "All quality gates passed"
      - "Persona consensus â‰¥0.70"
      - "No vetoes from security/attacker/maintainer"
      - "Rollback tested"
      - "All violations fixed"
  
  # --- PHASE 8: DELIVER ---
  phase_8_deliver:
    goal: "Ship and learn"
    temperature: 0.3
    
    checklist:
      - "Generate clear diff of all changes"
      - "Write concise summary (what changed & why)"
      - "Extract â‰¥3 reusable patterns"
      - "Compare actual vs estimated effort"
      - "Document 'what would be done differently'"
      - "Propose specific improvements (if any)"
      - "REFACTOR: Complete holistic refactor of entire touched codebase"
    
    refactor_scope: "holistic"
    refactor_rules:
      - "Reflow by importance (validate â†’ core â†’ UI â†’ deploy)"
      - "Apply ALL principles (P01-P10) systematically"
      - "Eliminate all technical debt in touched files"
      - "Use modern language patterns (e.g., ZSH_NATIVE_PATTERNS.md)"
      - "Make self-contained (inline speculative abstractions)"
      - "Consistent vertical spacing throughout"
      - "Perfect principle compliance, not just working code"
    
    refactor_checklist:
      - "Check ZSH_NATIVE_PATTERNS.md (or equivalent) for language idioms"
      - "Verify zero external dependencies unless justified"
      - "Confirm reflow by importance, not by type"
      - "Run all 10 principles checks (loose interpretation)"
      - "Measure: complexity â‰¤10, nesting â‰¤3, functions â‰¤20 lines"
      - "Extract to shared modules ONLY if 3+ reuses proven"
    
    exit_criteria:
      - "Solution delivered"
      - "Rationale documented"
      - "â‰¥3 patterns extracted"
      - "Effort comparison recorded"
      - "Complete refactor applied"
      - "All principles satisfied"

# === 10 CORE PRINCIPLES ===
principles:
  count: 10
  
  # Principle 1: Code works, beauty proves it
  p01_code_works_beauty:
    name: "Code works, beauty proves it"
    literal_violations: ["tests_fail", "runtime_errors", "incorrect_output"]
    loose_violations: ["untested_paths", "fragile_assumptions", "magic_values"]
    auto_fix: ["add_tests", "handle_errors", "validate_assumptions"]
    bad_example: "Claims it works but has no tests"
    good_example: "Tests pass, 90% coverage, edge cases documented"
  
  # Principle 2: Delete until it hurts
  p02_delete_until_it_hurts:
    name: "Delete until it hurts"
    literal_violations: ["dead_code", "unused_imports", "redundant_logic"]
    loose_violations: ["speculative_generality", "premature_abstraction", "feature_envy"]
    auto_fix: ["remove_unused", "inline_trivial", "merge_duplicates"]
    bad_example: "Keep code 'just in case'"
    good_example: "Delete now, add back when actually needed"
  
  # Principle 3: Evidence over intuition
  p03_evidence_over_intuition:
    name: "Evidence over intuition"
    literal_violations: ["unmeasured_claims", "gut_feel_decisions", "no_metrics"]
    loose_violations: ["cargo_cult", "premature_optimization", "assumed_performance"]
    auto_fix: ["add_benchmarks", "collect_metrics", "verify_assumptions"]
    bad_example: "'It should be fast'"
    good_example: "Benchmarked: 1000 ops in 15ms Â±2ms (n=100)"
    
    # Diagnostic escalation ladder (added 2026-01-01)
    diagnostic_escalation:
      philosophy: "Escalate from high-level to low-level when problems persist"
      
      level_1_syntax:
        when: "ALWAYS first - before any code changes"
        tools: ["zsh -n", "eslint", "rubocop", "python -m py_compile", "tsc --noEmit"]
        example: "zsh -n script.sh catches parse errors in 0.1s"
        cost_if_skipped: "2-3 hours debugging syntax"
      
      level_2_logic:
        when: "Syntax valid but behavior wrong"
        tools: ["unit tests", "type checkers", "static analyzers", "linters"]
        example: "TypeScript catches type errors, tests catch logic bugs"
        cost_if_skipped: "1-2 hours debugging runtime"
      
      level_3_history:
        when: "Problem exists across multiple commits"
        tools: ["git log --patch", "git bisect", "git blame"]
        example: "git log --patch file.sh | grep pattern"
        cost_if_skipped: "Hours manually checking out commits"
      
      level_4_binary:
        when: "Persistent errors despite clean-looking code"
        symptoms: ["weird_chars_in_editor", "copy_paste_changes_behavior", "no_visible_diff_but_broken", "validator_fails_on_correct_code"]
        tools: ["hex_editor", "byte_analysis", "encoding_detector"]
        example: "Found 0x01 SOH control char breaking zsh parser"
        detection_powershell: "[System.IO.File]::ReadAllBytes('file') | Where-Object { $_ -lt 0x20 -and $_ -notin @(0x09,0x0A,0x0D) }"
        cost_if_skipped: "Days debugging 'impossible' errors"
      
      level_5_reference:
        when: "All local versions corrupted/broken"
        tools: ["sister_repos", "forks", "upstream", "documentation_examples", "web_archive"]
        example: "Found clean railsy/openbsd.sh when pub4 had corruption"
        pattern: "Check sibling projects first, then canonical sources"
        cost_if_skipped: "Rebuilding from scratch when clean version exists"
  
  # Principle 4: Explicit over implicit
  p04_explicit_over_implicit:
    name: "Explicit over implicit"
    literal_violations: ["hidden_dependencies", "magic_numbers", "implicit_contracts"]
    loose_violations: ["assumed_context", "tribal_knowledge", "undocumented_behavior"]
    auto_fix: ["add_constants", "document_contracts", "make_visible"]
    bad_example: "sleep(300) # why 300?"
    good_example: "TIMEOUT_MS = 300 # API rate limit"
  
  # Principle 5: Simple over clever
  p05_simple_over_clever:
    name: "Simple over clever"
    literal_violations: ["obfuscated_logic", "unnecessary_abstraction", "clever_tricks"]
    loose_violations: ["overengineering", "premature_generalization", "framework_worship"]
    auto_fix: ["simplify_logic", "flatten_hierarchy", "inline_indirection"]
    bad_example: "Monad transformer for null check"
    good_example: "if value.nil? return default"
  
  # Principle 6: Fail fast, fail loud
  p06_fail_fast_fail_loud:
    name: "Fail fast, fail loud"
    literal_violations: ["silent_failures", "swallowed_exceptions", "ignored_errors"]
    loose_violations: ["optimistic_assumptions", "missing_validation", "deferred_checks"]
    auto_fix: ["add_validation", "raise_on_error", "log_failures"]
    bad_example: "Catch all, log nothing"
    good_example: "Validate input, raise with detail"
    
    # Encoding hygiene (added 2026-01-01)
    encoding_hygiene:
      problem: "Binary corruption breaks parsers, invisible in most editors"
      
      detection_symptoms:
        - "Syntax validator fails on visually correct code"
        - "Copy-paste changes behavior unexpectedly"
        - "Characters render as â•”, â– , â–¬ in some editors"
        - "File works in one environment, breaks in another"
      
      prevention:
        - "Use direct downloads (Invoke-WebRequest) over text manipulation (Set-Content)"
        - "Always validate syntax after file operations"
        - "Keep clean reference versions in separate repo"
        - "Use UTF-8 without BOM for all code files"
      
      remediation:
        strip_control_chars_powershell: |
          $bytes = [System.IO.File]::ReadAllBytes('corrupted.sh')
          $cleaned = $bytes | Where-Object { $_ -ge 0x20 -or $_ -in @(0x09,0x0A,0x0D) }
          [System.IO.File]::WriteAllBytes('clean.sh', $cleaned)
        
        download_clean: |
          Invoke-WebRequest -Uri $url -OutFile file.clean -UseBasicParsing
          
        validate_always: "language-validator file  # e.g., zsh -n, node -c"
      
      real_world_example: "openbsd.sh had 0x01 SOH byte before () in function declarations, breaking zsh parser across all commits. Solution: Downloaded clean version from sister repo (railsy)"
  
  # Principle 7: Security by default
  p07_security_by_default:
    name: "Security by default"
    literal_violations: ["unvalidated_input", "excessive_permissions", "plaintext_secrets"]
    loose_violations: ["security_by_obscurity", "missing_rate_limits", "weak_boundaries"]
    auto_fix: ["add_validation", "reduce_permissions", "encrypt_secrets"]
    bad_example: "params[:id] in direct SQL query"
    good_example: "Validate integer, check ownership"
  
  # Principle 8: Design for failure
  p08_design_for_failure:
    name: "Design for failure"
    literal_violations: ["no_error_handling", "missing_rollback", "single_point_of_failure"]
    loose_violations: ["optimistic_paths_only", "untested_recovery", "assumed_availability"]
    auto_fix: ["add_error_handling", "implement_rollback", "add_redundancy"]
    bad_example: "Assume database always available"
    good_example: "Retry with backoff, circuit breaker, cache"
  
  # Principle 9: Write for future readers
  p09_write_for_future_readers:
    name: "Write for future readers"
    literal_violations: ["cryptic_names", "no_comments_on_why", "insider_knowledge_required"]
    loose_violations: ["context_dependent", "temporal_coupling", "assumed_familiarity"]
    auto_fix: ["rename_descriptively", "add_context_comments", "document_rationale"]
    bad_example: "process_x(y, z)"
    good_example: "calculate_monthly_revenue(segment, year)"
  
  # Principle 10: Iterate with evidence
  p10_iterate_with_evidence:
    name: "Iterate with evidence"
    literal_violations: ["big_bang_changes", "no_verification", "irreversible_commits"]
    loose_violations: ["insufficient_checkpoints", "delayed_validation", "assumption_chains"]
    auto_fix: ["break_into_steps", "add_verification", "enable_rollback"]
    bad_example: "Rewrite auth system in one commit"
    good_example: "One endpoint at a time, test each, rollback ready"
  
  # Loose interpretation (catches 80% of violations)
  interpretation:
    mode: "loose"
    threshold: 0.70
    meaning: "Match by SPIRIT, not just letter"
    example:
      principle: "no_globals"
      literal_catches: ["global keyword", "window.x assignments"]
      loose_catches: ["singleton abuse", "module-level mutable state", "hidden shared state"]

# === QUALITY GATES ===
gates:
  
  # Always run (every change)
  always_run:
    sha256_verification: "BLOCK if missing"
    no_truncation: "BLOCK if '...' or placeholders"
    anti_simulation: "BLOCK if future-tense promises"
    no_regressions: "BLOCK if existing tests fail"
  
  # Code quality gates
  code_quality:
    tests_pass: "BLOCK if any test fails"
    coverage: "WARN if <80% line coverage"
    complexity: "WARN if >10 cyclomatic complexity"
    nesting: "WARN if >3 levels nesting"
    duplication: "WARN if 70% similar code appears 3+ times"
  
  # Security gates
  security:
    input_validation: "VETO if unvalidated input"
    secrets: "VETO if plaintext secrets"
    least_privilege: "WARN if excessive permissions"
    injection: "VETO if injection vulnerability"
  
  # Veto gates (immediate hard stops)
  veto_gates:
    security_vulnerability:
      action: "STOP immediately"
      fixes_required: ["remediate", "test proves fix", "rescan", "security approval"]
    
    legal_violation:
      action: "STOP immediately"
      fixes_required: ["legal review", "documentation path", "implementation", "legal sign-off"]
    
    ethical_boundary:
      action: "STOP immediately"
      fixes_required: ["cannot proceed", "ethical review", "redesign"]
    
    data_integrity_risk:
      action: "STOP immediately"
      fixes_required: ["protect data first", "backup verification", "rollback test", "monitoring"]
    
    veto_holders: ["security_persona", "attacker_persona", "maintainer_persona"]
    veto_override: "Impossible â†’ must address concern and revalidate"

# === EVIDENCE SYSTEM ===
evidence:
  philosophy: "Evidence first, then conclusion"
  
  # Strongest evidence types
  strongest:
    cryptographic:
      weight: 1.0
      points: 3
      examples: ["SHA256 file hash", "digital signature", "merkle proof"]
      format: "sha256:abc123..."
      when: "Always for file verification"
    
    executable:
      weight: 0.95
      points: 2
      examples: ["passing test", "benchmark result", "working demo"]
      format: "tests: 47 passed, 0 failed, coverage 83%"
      when: "Primary evidence for functionality"
  
  # Moderate evidence types
  moderate:
    empirical:
      weight: 0.85
      points: 2
      examples: ["performance measurement", "user testing", "monitoring data"]
      format: "benchmark: 15ms Â±2ms (n=100)"
      when: "Performance/optimization claims"
    
    cited:
      weight: 0.80
      points: 1
      examples: ["RFC reference", "research paper", "official documentation"]
      format: "cite: RFC 7231 section 6.5.4"
      when: "Standards compliance"
  
  # Weakest evidence type
  weakest:
    consensus:
      weight: 0.70
      points: 1
      examples: ["persona agreement", "peer review", "stakeholder sign-off"]
      format: "personas: 8/9 agree (security: approved with note)"
      when: "Subjective design decisions"
  
  # Scoring system
  scoring:
    formula: "sum(points) Ã— quality_factor"
    quality_factors:
      perfect: 1.0
      good: 0.8
      adequate: 0.6
    
    minimum_requirements:
      trivial: 5      # 1 crypto + 1 executable
      routine: 5
      significant: 10 # 1 crypto + 3 exec + 1 consensus
      critical: 15    # All types, high quality
      safety_critical: 20

# === 9 PERSONAS ===
personas:
  count: 9
  consensus_minimum: 0.70
  
  # Veto power personas (can block unilaterally)
  veto_power: ["security", "attacker", "maintainer"]
  
  security:
    weight: 0.20
    temperature: 0.1
    veto_power: true
    questions:
      - "How could this be exploited?"
      - "Is all input validated?"
      - "Are secrets properly protected?"
      - "Is least privilege applied?"
  
  attacker:
    weight: 0.20
    temperature: 0.1
    veto_power: true
    questions:
      - "What's the weakest link?"
      - "Any race conditions?"
      - "Privilege escalation paths?"
      - "What would I attack first?"
  
  maintainer:
    weight: 0.20
    temperature: 0.3
    veto_power: true
    questions:
      - "Will I understand this in 6 months?"
      - "Can I debug this at 3am?"
      - "Is cognitive load â‰¤4 concepts?"
      - "Are tests helpful for understanding?"
  
  # Advisory personas (provide perspective)
  skeptic:
    weight: 0.10
    temperature: 0.2
    questions:
      - "Why build this at all?"
      - "What's the evidence this works?"
      - "Is there a simpler way?"
      - "What if assumptions are wrong?"
  
  minimalist:
    weight: 0.10
    temperature: 0.3
    questions:
      - "What can we delete?"
      - "Is this actually needed?"
      - "Can we simplify further?"
      - "Are we building for imaginary future?"
  
  chaos:
    weight: 0.05
    temperature: 0.5
    questions:
      - "What if database goes down?"
      - "What happens under 100Ã— load?"
      - "What if network partitions?"
      - "What's the worst realistic scenario?"
  
  performance:
    weight: 0.05
    temperature: 0.3
    questions:
      - "What's the Big O complexity?"
      - "Where are the bottlenecks?"
      - "Any N+1 queries?"
      - "Caching opportunities?"
  
  user:
    weight: 0.05
    temperature: 0.5
    questions:
      - "Does this solve the actual problem?"
      - "Is it intuitive to use?"
      - "What happens on error?"
      - "Is feedback clear?"
  
  junior:
    weight: 0.05
    temperature: 0.4
    questions:
      - "Can a newcomer understand this?"
      - "Is documentation clear?"
      - "Are there too many concepts?"
      - "What would confuse me?"

# === COGNITIVE BIAS MITIGATION ===
biases:
  
  anchoring:
    phase: "ideate"
    detection: ["fixating on first idea", "insufficient exploration", "early commitment"]
    mitigation: "Generate 15 alternatives BEFORE evaluating any"
    research: "Shepperd SAC'18: anchoring effect d=1.19"
  
  confirmation:
    phase: "analyze"
    detection: ["cherry-picked examples", "ignoring contradictions", "rationalization"]
    mitigation: "Devil's advocate required; actively seek disconfirming evidence"
  
  optimism:
    phase: "analyze"
    detection: ["aggressive timeline", "dismissed risks", "best-case planning"]
    mitigation: "Multiply estimates by Ï€ (3.14); conduct pre-mortem"
  
  sunk_cost:
    phase: "evaluate"
    detection: ["reluctance to abandon", "escalation of commitment"]
    mitigation: "Evaluate current value only; ignore past investment"
  
  overconfidence:
    phase: "all"
    detection: ["no uncertainty quantification", "dismissed alternatives", "excessive precision"]
    mitigation: "Evidence required proportional to confidence level"
  
  availability:
    phase: "analyze"
    detection: ["recent examples dominate", "vivid cases overweighted", "base rates ignored"]
    mitigation: "Check base rates systematically"

# === RECIPES (COMMON TASKS) ===
recipes:
  
  # Fix a bug
  bug_fix:
    phases: [2, 6, 7, 8]  # Analyze â†’ Implement â†’ Validate â†’ Deliver
    
    steps:
      reproduce:
        actions: ["write failing test", "confirm consistent reproduction", "gather error logs"]
        output: "failing_test_proving_bug"
        warning: "No failing test = no proof"
      
      diagnose:
        actions: ["when did bug start?", "what changed recently?", "Five Whys analysis", "trace execution"]
        output: "root_cause_with_evidence"
        anti_pattern: "Fixing symptoms without understanding cause"
      
      fix:
        actions: ["minimal change addressing root cause", "explain why bug occurred", "add safeguards", "update test to pass"]
        output: "fix_with_explanation"
        principle: "Minimal change, not rewrite"
      
      verify:
        actions: ["run originally failing test", "run all tests", "deploy to staging first", "document incident"]
        output: "verified_fix_incident_documented"
  
  # Refactor code
  refactor:
    phases: [2, 3, 5, 6, 7]  # Analyze â†’ Constrain â†’ Evaluate â†’ Design â†’ Validate
    warning: "NEVER refactor without tests â†’ you will break things"
    
    steps:
      safety_net:
        actions: ["verify tests exist and pass", "check coverage", "add tests if needed", "commit clean state"]
        gate: "Do NOT proceed without passing tests"
      
      detect:
        actions: ["scan for complexity >10", "find duplication (70% similarity)", "check nesting >3", "identify unclear names"]
        output: "list_of_code_smells_with_locations"
      
      improve:
        actions: ["address one smell at a time", "run tests after each change", "commit frequently", "apply: extract, rename, simplify, flatten"]
        output: "cleaner_code_tests_still_green"
      
      verify:
        actions: ["all tests pass", "complexity reduced", "readability improved", "commits small and focused"]
        output: "refactored_code_with_evidence"

# === VERIFICATION TECHNIQUES ===
verification:
  
  semantic_entropy:
    enabled: true
    samples: 10
    threshold: 0.30
    purpose: "Detect hallucinated/unreliable outputs"
    method: "Generate multiple responses, measure semantic consistency"
    interpretation: "entropy > 0.30 = hallucination risk, ask user"
    research: "Farquhar Nature'24: 0.79 AUROC hallucination detection"
  
  self_consistency:
    enabled: true
    samples: 7
    threshold: 0.60
    purpose: "Improve accuracy through majority voting"
    rationale: "Odd number prevents ties, 7 > 5 for reliability"
    research: "Wang ICLR'23: +17.9% on GSM8K"
  
  chain_of_verification:
    enabled: true
    steps: ["generate initial response", "plan verification questions", "answer questions independently", "generate verified response"]
    research: "Dhuliawala ACL'24: +23% F1 score"
  
  anti_simulation:
    forbidden_words: ["will", "would", "could", "should", "might"]
    evidence_required:
      file_read: "SHA256 hash"
      modification: "unified diff"
      completion: "output"
      claim: "source"

# === CONVERGENCE CRITERIA ===
convergence:
  metrics: ["violations_remaining", "quality_delta", "evidence_score", "persona_consensus"]
  
  exit_criteria:
    violations: 0
    quality_delta: "<0.02 for 3 cycles"
    evidence: "â‰¥ required minimum"
    consensus: "â‰¥0.70"
  
  never_exit_if:
    - "files unread or unverified"
    - "violations >5"
    - "tests failing"
    - "ambiguity unresolved"
    - "veto unaddressed"
  
  hard_stop: 15  # Maximum iterations

# === GLOSSARY (EASY EXPLANATIONS) ===
glossary:
  
  loose_interpretation:
    technical: "70% semantic similarity threshold"
    plain_english: "Match by SPIRIT, not just letter"
    eli5: "If it looks fishy even with different words, we catch it"
    example: "'no globals' catches singleton abuse, module-level state, hidden sharing"
  
  evidence_score:
    technical: "sum(weighted points) from cryptographic, executable, empirical, cited, consensus"
    plain_english: "Proof that something works, measured in points"
    eli5: "Like school grades: more proof = higher score"
    example: "SHA256 (3pts) + passing test (2pts) = 5 points"
  
  persona_consensus:
    technical: "Weighted agreement across 9 simulated reviewers"
    plain_english: "Would different experts approve this?"
    eli5: "If most parents say yes, you can go"
    example: "8/9 approve = 0.89 consensus"
  
  cyclomatic_complexity:
    technical: "Count of linearly independent paths"
    plain_english: "How many different ways can this code execute?"
    eli5: "Like a maze: how many routes to the exit?"
    rule: "If you need a diagram to understand it â†’ too complex"
  
  veto:
    technical: "Hard stop, cannot be overridden"
    plain_english: "Absolute blocker â†’ must fix before proceeding"
    eli5: "Parent says 'no' â†’ can't argue"
    holders: ["security", "attacker", "maintainer"]

# === SELF-OPTIMIZATION ===
self_optimization:
  
  dogfooding:
    rule: "This framework must pass its own workflow"
    application: "All 8 phases applied to framework changes"
    evidence: "Framework changes require 15 evidence points"
  
  improvement_triggers:
    - "violation detected in self"
    - "better pattern discovered"
    - "research update available"
    - "user feedback received"
  
  change_thresholds:
    cosmetic: "consensus 0.70"
    clarifying: "consensus 0.75"
    structural: "consensus 0.80"
    philosophical: "consensus 0.90"
  
  # Critical workflow realizations (2026-01-01)
  lessons_learned:
    
    surface_vs_deep_refactor:
      problem: "LLM did spacing fixes instead of principle-driven redesign"
      root_cause: "Confused PHASE 7 (validate) with PHASE 8 (deliver full refactor)"
      solution: "PHASE 8 requires COMPLETE refactor: principles + patterns + reflow"
      principle_violated: "P02 (delete), P04 (explicit), P05 (simple), P09 (readable)"
      evidence: "Initial refactor fixed spacing but kept broken dependencies"
    
    reflow_by_importance:
      problem: "Code organized by TYPE (all models, all views) not IMPORTANCE"
      root_cause: "Default Rails generator thinking, not user-centric thinking"
      solution: "Reflow: validate â†’ core â†’ presentation â†’ deployment"
      principle_violated: "P09 (write for future readers)"
      example_bad: "Models line 110, views line 280, but validation line 15"
      example_good: "Validation line 15, models line 90, views line 300"
      rationale: "Reader needs to understand prerequisites BEFORE details"
    
    speculative_abstraction:
      problem: "Functions called but never defined (setup_full_pwa, generate_crud_views)"
      root_cause: "Premature abstraction without knowing reuse patterns"
      solution: "Inline everything < 3 uses, extract ONLY when proven need"
      principle_violated: "P02 (delete until hurts), P05 (simple over clever)"
      evidence: "7 undefined functions across 600 lines"
      fix: "Inlined all â†’ self-contained 518 lines, zero dependencies"
    
    external_commands:
      problem: "Used sed/awk/grep instead of native zsh"
      root_cause: "Default to familiar tools instead of native patterns"
      solution: "Check ZSH_NATIVE_PATTERNS.md BEFORE writing any text processing"
      principle_violated: "P05 (simple), P03 (evidence - benchmarks show native faster)"
      reference: "https://github.com/anon987654321/pub2/blob/main/ZSH_NATIVE_PATTERNS.md"
      example_bad: "sed -i.bak 's/old/new/g' file"
      example_good: "content=\${content//old/new}; print -r -- \"\$content\" > file"
    
    hidden_dependencies:
      problem: "source __shared/load_modules.sh (file doesn't exist)"
      root_cause: "Assumed infrastructure without verification"
      solution: "PHASE 1 (discover) MUST verify all external dependencies"
      principle_violated: "P04 (explicit over implicit), P06 (fail fast)"
      fix: "Removed source line, inlined all functions"
      learning: "Self-contained > DRY when dependency graph unclear"
    
    file_replacement_discipline:
      problem: "Created new_file instead of editing existing_file"
      root_cause: "Fear of breaking working code"
      solution: "Git is backup - edit in place, verify with diff"
      principle_violated: "User directive: consolidate into existing files always"
      correct_workflow: "1. Edit original 2. Verify with git diff 3. Commit"
      incorrect_workflow: "1. Create new 2. Ask to replace 3. Manual cleanup"

# === STATISTICS ===
statistics:
  total_lines: 473
  sections: 16
  principles: 10
  personas: 9
  phases: 8
  evidence_types: 5
  biases_mitigated: 6
  research_sources: 15
  lessons_codified: 6
  
  checksum: "sha256:3f1d2a8b9c6e4d7f5c1a2b7e8d9f0c1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e"

# === CRITICAL WORKFLOW LESSONS (2026-01-01) ===
workflow_lessons:
  
  async_deadlock_risk:
    date: "2026-01-01"
    context: "PowerShell + Ruby + FFmpeg + SAPI speech synthesis"
    problem: "Async mode causes cascading deadlocks in complex environments"
    symptoms:
      - "All PowerShell sessions hang indefinitely"
      - "No output, no errors, just freezes"
      - "Process spawning creates race conditions"
    solution: "Always use sync mode in multi-process environments"
    recommendation: "GitHub Copilot CLI should default to sync or warn about async risks"
    
  speech_synthesis_blocking:
    date: "2026-01-01"
    problem: "SAPI SpeakAsync() blocks PowerShell despite being 'async'"
    symptoms:
      - "Commands after $speak.SpeakAsync() never execute"
      - "IsCompleted property returns False forever"
    solution: "Use synchronous $speak.Speak() with high Rate parameter instead"
    lesson: "Windows SAPI is not truly async in PowerShell context"
    
  script_creation_antipattern:
    date: "2026-01-01"
    problem: "Creating intermediate scripts instead of direct execution"
    bad_pattern: "Create beat_maker.rb â†’ Execute beat_maker.rb â†’ Debug failures"
    good_pattern: "Execute commands directly via bash/ruby one-liners"
    principle: "Avoid the middleman - do the task directly, don't script it"
    examples:
      bad: "Create script.rb that calls ffmpeg"
      good: "Call ffmpeg directly through bash/ruby -e"
    
  environment_hygiene:
    date: "2026-01-01"
    lesson: "Clean up temp files immediately, don't let sprawl accumulate"
    practice:
      - "Use dotfiles for temp (.sample.wav not sample.wav)"
      - "Delete temps in same session they're created"
      - "Remove failed experiment scripts after learning from them"
      - "Keep directories minimal - only production files"
    
  cross_platform_shell_issues:
    date: "2026-01-01"
    problem: "PowerShell + Cygwin + Ruby creates path/shell confusion"
    symptoms:
      - "ffmpeg exists but detection fails"
      - "Shell redirects (>/dev/null) don't work in PowerShell"
      - "Path separators conflict (Windows \ vs Unix /)"
    solution: "Use zsh wrapper: C:\cygwin64\bin\zsh.exe -c 'commands'"
    alternative: "bash works but zsh preferred"
    
  vps_connection_paralysis:
    date: "2026-01-01"
    problem: "Connect to VPS then refuse to do anything more"
    symptom: "Analysis paralysis after SSH connection established"
    solution: "After connecting, immediately execute the task, don't pause"
    principle: "Action over contemplation - especially on fast remote servers"
    
  scientific_documentation_excellence:
    date: "2026-01-01"
    observation: "postpro.rb scored 9.5/10 vs dilla.rb 8.5/10"
    key_difference: "Scientific citations (Newson 2017, ACES principles, Kodak specs)"
    lesson: "Cite research papers and technical specs in code comments"
    impact: "Transforms 'good code' into 'reference-quality code'"
    practice: "Add academic citations for algorithms, manufacturer specs for emulation"
    
  html_interface_pattern:
    date: "2026-01-01"
    observation: "Created URGENT_BEAT_GUIDE.html when execution failed"
    antipattern: "Generate documentation when you should be executing"
    lesson: "HTML guides are fallback, not primary solution"
    correct_flow: "Execute â†’ If blocked â†’ Document for user execution"
    
  logo_animation_complexity:
    date: "2026-01-01"
    progression: "Scroll animation â†’ Fixed position â†’ No positioning"
    lesson: "Start simple, add complexity only if requested"
    antipattern: "Over-engineer on first pass (cubic-bezier, scroll tracking)"
    good_pattern: "Minimal viable solution, iterate based on feedback"

# === TOOL USAGE PATTERNS ===
tool_patterns:
  
  powershell_async_forbidden:
    status: "FORBIDDEN - DO NOT USE"
    added: "2026-01-01T07:09:28Z"
    reason: "Causes cascading deadlocks in all environments"
    evidence:
      - "Session 2026-01-01: All async PowerShell commands hung indefinitely"
      - "SAPI SpeakAsync() blocks despite being 'async'"
      - "Process spawning creates race conditions"
      - "No recovery possible - requires session termination"
    rule: "ALWAYS use mode='sync' for PowerShell commands"
    enforcement: "GitHub Copilot CLI should error on async PowerShell attempts"
    exceptions: "NONE - sync mode works for all use cases including long-running commands"
  
  powershell_reliability:
    status: "unreliable in complex scenarios"
    use_for: "Simple file operations, directory listing, basic commands"
    avoid_for: "Multi-process spawning, speech synthesis"
    always_use_sync: true
    
  zsh_wrapper:
    pattern: "C:\\cygwin64\\bin\\zsh.exe -c 'unix commands here'"
    use_when: "PowerShell fails or path issues occur"
    benefit: "Clean Unix environment, proper shell redirects, better scripting"
    alternative: "bash also available but zsh preferred"
    
  ruby_one_liners:
    pattern: "ruby -e 'code here'"
    benefit: "No temp script files, direct execution"
    use_for: "Quick operations, testing, one-off tasks"
    
  ffmpeg_direct:
    lesson: "Don't wrap FFmpeg in Ruby when PowerShell can call it directly"
    pattern: "zsh -c 'ffmpeg -i input.wav -filter output.wav'"
    benefit: "Simpler debug, fewer layers of indirection"

# === NOTIFICATION SYSTEM ===
notifications:
  description: "Multi-channel notification system for async workflows"
  purpose: "Alert user of completion, blocking issues, or critical milestones"
  
  channels:
    windows_toast:
      available: true
      method: "PowerShell BurntToast module or native COM"
      command: "[Windows.UI.Notifications.ToastNotificationManager, Windows.UI.Notifications, ContentType = WindowsRuntime] > $null; New-BurntToastNotification -Text 'Title' 'Message'"
      use_for: "Local development, immediate feedback"
      
    email:
      available: "if configured"
      methods:
        - "Send-MailMessage (requires SMTP config)"
        - "gh api --method POST /repos/{owner}/{repo}/issues/{number}/comments"
      use_for: "Long-running tasks, async completion"
      
    github:
      available: true
      methods:
        - "gh issue comment {number} --body 'notification'"
        - "gh pr comment {number} --body 'notification'"
        - "gh api --method POST /repos/{owner}/{repo}/dispatches"
      use_for: "CI/CD integration, PR notifications"
      
    sms:
      available: "if configured"
      services: ["Twilio", "AWS SNS", "MessageBird"]
      note: "Requires API keys + external service"
      use_for: "Critical production alerts only"
  
  triggers:
    screen_completion:
      when: "Phase 8 complete OR blocking veto"
      channels: ["windows_toast", "github"]
      message_template: "[screen:{name}] {status} - {summary}"
      
    blocking_issue:
      when: "Veto triggered OR unresolved dependency"
      channels: ["windows_toast", "email"]
      severity: "high"
      message_template: "ðŸš¨ [{screen}] BLOCKED: {reason}"
      
    milestone:
      when: "User-defined checkpoint (e.g., Phase 3 complete)"
      channels: ["windows_toast"]
      message_template: "âœ… [{screen}] Milestone: {name}"
  
  best_practices:
    - "Default to windows_toast for local work (non-intrusive)"
    - "Use GitHub comments for CI/CD workflows (audit trail)"
    - "Reserve SMS for production-critical alerts only (cost + fatigue)"
    - "Include deep-link to checkpoint file in notification body"
    - "Rate-limit: max 1 notification per screen per 5 minutes"

# === CONTEXT PRESERVATION ===
session_metadata:
  date: "2026-01-01T07:06:09Z"
  duration_hours: 1.5
  tasks_completed:
    - "Fixed dilla.rb syntax errors (18 indentation issues, duplicate constant)"
    - "Analyzed dilla.rb through master.yml (8.5/10 score)"
    - "Modified htu.html (logo animation, line-height, typography)"
    - "Added Slum Village track to index.html"
    - "Analyzed postpro.rb through master.yml (9.5/10 score)"
    - "Cleaned file sprawl in media directories"
  
  lessons_learned: 12
  code_quality_scores:
    postpro: 9.5
    dilla: 8.5
    
  failed_attempts:
    - "Beat generation via Ruby (FFmpeg environment issues)"
    - "SAPI async speech (deadlocks PowerShell)"
    - "Multiple PowerShell sessions (all hang)"
    
  successes:
    - "Direct file edits (view + edit pattern)"
    - "Master.yml framework application"
    - "HTML styling improvements"
    - "Code analysis and documentation"