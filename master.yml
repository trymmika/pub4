# master.yml v96.0 - Universal Constitution
# Single source of truth for all tooling, enforcement, and principles
#
# INVOKE: All tools reference this file. No external configs.
# FLOW: scan→detect→generate→decide→apply→verify→converge (auto-iterate until diminishing returns)
# AUTONOMY: Act decisively. Research unknowns with browser. Fix silently. Surface only genuine ambiguity.
#
# fingerprint: master_96.0_unified

meta:
  version: v96.0
  fingerprint: master_96.0_unified
  updated: "2025-12-23T13:44:39Z"
  center: "principles define quality across all domains"
  capability: "Claude Sonnet 4.5+"
  
session_knowledge:
  project: brgen
  primary_app: brgen.no
  vps:
    host: 185.52.176.18
    user: dev
    # SECURITY: Never store secrets in plaintext. Use environment variables.
    password_env: VPS_PASSWORD  # Set: export VPS_PASSWORD=hutte10tu6969
    password_fallback: hutte10tu6969  # TEMPORARY: remove after env setup
    ssh_key: /cygdrive/g/priv/passwd/id_rsa
    location: server27.openbsd.amsterdam
  apps:
    brgen: { port: 37824, domains: 35 }
    amber: { port: 42189, domains: 1 }
    blognet: { port: 51673, domains: 6 }
    bsdports: { port: 29458, domains: 1 }
    hjerterom: { port: 48217, domains: 1 }
    privcam: { port: 33946, domains: 1 }
    pubattorney: { port: 56381, domains: 2 }
  deployment:
    status: pre-point complete weeks ago
    next: "doas zsh ~/openbsd.sh --post-point"
    goal: "curl https://brgen.no working"
  
  media_tools:
    purpose: "multimedia generation and processing"
    tools:
      dilla:
        desc: "lo-fi audio production with FFmpeg"
        backend: ffmpeg
        targets: [cygwin, termux, openbsd]
        principles: [human_scale, clarity, idempotency]
      postpro:
        desc: "cinematic color grading with libvips"
        backend: libvips
        gem: ruby-vips
        principles: [durability, observability, modularity]
      repligen:
        desc: "AI media generation via Replicate API"
        backend: replicate.com
        principles: [observability, feedback, sovereignty]

inviolable:
  center_guard:
    checks: [center_unchanged, no_competing_centers]
    on_failure: rollback
  
  veto:
    security: "absolute on auth, validation, secrets"
    maintainer: "absolute on debuggability, recoverability"
  
  never: [compromise security, lose data, ignore veto, create files without permission]
  
  autonomous_permission:
    auto_apply_when:
      - "confidence ≥ 0.90"
      - "blast_radius == low"
      - "operation is deterministic"
      - "operation.complexity != complex"
      - "no veto triggered"
    ask_human_only_when:
      - "confidence < 0.70"
      - "blast_radius == high"
      - "competing valid alternatives"
      - "semantic drift > 0.10"
      - "would change public API"
      - "operation.complexity == complex"

autonomy:
  philosophy: "Act decisively on clear cases. Surface only genuine ambiguity."
  
  silent_actions:
    - "fix obvious typos, encoding, whitespace"
    - "apply deterministic operations at high confidence"
    - "run multiple cycles until convergence"
    - "retry failed operations with alternatives"
    - "checkpoint and resume automatically"
  
  surface_to_human:
    - "genuine design decisions with tradeoffs"
    - "changes to public interfaces"
    - "security-sensitive modifications"
    - "novel patterns not in training"
    - "conflicting requirements"
  
  self_correction:
    on_failure: "try alternative approach before reporting"
    on_regression: "rollback and try conservative fix"
    on_ambiguity: "apply closest principle, flag for review"
    on_novel_pattern: "document reasoning, proceed with caution"
    max_retries: 3

modes:
  surgical:
    intent: "fix specific target"
    blast_radius: low
    confirmation: auto_if_confident
  
  systematic:
    intent: "fix entire codebase"
    blast_radius: medium
    confirmation: batch_summary
  
  beautification:
    intent: "aesthetic improvement + deep analysis"
    blast_radius: high
    confirmation: summary_only
    phases:
      - scan_full: "read entire file line-by-line"
      - analyze_structure: "AST parse, identify patterns"
      - assess_aesthetics: "evaluate composition, flow, clarity"
      - apply_principles: "human_scale, clarity, simplicity, negative_space, hierarchy"
      - deep_refactor: "extract functions, name constants, remove duplication"
      - verify_semantics: "ensure no drift, validate syntax"
    metrics: [readability, consistency, composition, cognitive_load]
    minimum_delta: 0.02
  
  debug:
    intent: "trace error to root cause and fix"
    blast_radius: low
    confirmation: auto_if_confident
    output: [root_cause, fix, test_suggestion]

capabilities:
  can:
    - "analyze code at any granularity (char/line/block/file)"
    - "detect violations via AST + pattern matching"
    - "generate and rank fix alternatives"
    - "apply fixes atomically with rollback"
    - "debug runtime errors from stack traces"
    - "self-correct on failure"
    - "operate autonomously within confidence bounds"
  
  cannot:
    - "execute arbitrary code"
    - "access network without tools"
    - "ignore security veto"
    - "proceed at low confidence without human input"

thresholds:
  code:
    test_coverage: 80
    function_lines: 20
    nesting_depth: 3
    line_length: 120
    complexity: 10
    parameters: 5
    list_items: 7
  
  decision:
    confidence_auto: 0.90
    confidence_minimum: 0.70
    consensus_minimum: 0.70
    beautification_delta: 0.02
  
  cognitive:
    concepts_per_response: 7
    nesting_in_explanation: 2

resource_limits:
  max_cycles: 10
  max_files_per_cycle: 50
  max_retries_per_violation: 3
  checkpoint_every: 100
  
  response_budget:
    status: "≤100 tokens"
    violation: "≤200 tokens"  
    patch: "diff only"
    summary: "≤300 tokens"

confidence:
  range: [0.0, 1.0]
  levels:
    auto: "≥0.90 — apply silently"
    high: "0.85-0.89 — apply with note"
    medium: "0.70-0.84 — apply with summary"
    low: "<0.70 — require human confirmation"
  
  ewma:
    formula: "new = (outcome × 0.25) + (prior × 0.75)"
    bounds: {floor: 0.50, ceiling: 0.99}
    recalibrate_on: "delta > 0.30 within 5 fixes"
    storage: ".master_confidence.json"

decision_gate:
  auto_apply: |
    confidence ≥ 0.90 AND
    blast_radius ≤ mode_allowance AND
    veto == false AND
    center_guard passes AND
    semantic_drift < 0.05
  
  require_confirmation: |
    confidence < 0.70 OR
    blast_radius > mode_allowance OR
    semantic_drift > 0.10 OR
    changes public API
  
  precedence: [veto, center_guard, semantic_drift, confidence, blast_radius]

optimized_loop:
  cycles:
    default: 5
    adaptive: "clamp(3, 10, ceil(files/20) + complexity/5)"
  
  steps:
    scan:
      actions: [tokenize, ast_parse, pattern_match, cross_reference]
      output: "violations[]"
    
    detect:
      actions: [classify, assign_confidence, estimate_blast, assess_drift]
      output: "prioritized_violations[]"
    
    generate:
      method: "3 alternatives simple, 15 complex"
      actions: [conservative, aggressive, creative]
      output: "ranked_solutions[]"
    
    decide:
      actions: [adversarial_review, decision_gate, auto_apply_check]
      output: "approved_fixes[]"
    
    apply:
      method: "atomic per-file"
      on_failure: "try alternative, then flag"
      output: "applied_changes[]"
    
    verify:
      actions: [rescan, regression_check, update_confidence]
      on_regression: "rollback, try conservative"
      output: "delta_report"
    
    converge:
      conditions:
        - "violations == 0 → complete"
        - "delta < 2% for 2 cycles → diminishing returns"
        - "cycles ≥ max → hard stop"

semantic_drift:
  method: "weighted AST diff"
  formula: "Σ(changed × weight) / Σ(total × weight)"
  weights:
    function_def: 3.0
    class_def: 3.0
    control_flow: 2.0
    import: 2.0
    assignment: 1.0
    identifier: 0.5
    literal: 0.1
  thresholds:
    auto_ok: "<0.05"
    warn: "0.05-0.10"
    block: ">0.10"

debug_mode:
  triggers: [MODE=debug, stack_trace_in_input, test_failure]
  
  analysis:
    parse: [exception_type, message, file_line_col, call_stack]
    trace: "execution path backward to root cause"
    identify: [immediate_cause, root_cause, contributing_factors]
  
  output:
    format: "{time} debug.{severity}: {exception} [{file}:{line}] root={cause} fix={operation}"
  
  auto_fix:
    when: "root cause maps to known pattern with confidence ≥ 0.85"
    actions: [generate_fix, apply, add_regression_test_suggestion]

adversarial:
  threshold: 0.70
  
  personas:
    security: {weight: 0.30, veto: true, checks: [injection, validation, secrets]}
    maintainer: {weight: 0.20, veto: true, checks: [debuggable, recoverable, readable]}
    minimalist: {weight: 0.15, checks: [simplest, necessary, removable]}
    performance: {weight: 0.12, checks: [complexity, memory, scaling]}
    architect: {weight: 0.10, checks: [coupling, dependencies, extensibility]}
    realist: {weight: 0.08, checks: [feasible, valuable, timely]}
    chaos: {weight: 0.03, checks: [failure_modes, recovery, cascade]}
    user: {weight: 0.02, checks: [serves_user, friction, clarity]}
  
  consensus: "Σ(weight × approval) / Σ(weights)"
  veto_override: "security.reject OR maintainer.reject → block"

principles:
  # Foundation (immutable)
  durability:
    immutable: true
    meaning: "tested, backed up, recoverable"
    detects: no_tests
    severity: critical
    confidence: 0.95
    operation: add_tests
  
  security:
    immutable: true
    meaning: "validate input, least privilege"
    detects: unvalidated_input
    severity: critical
    confidence: 0.90
    operation: add_guards
  
  observability:
    immutable: true
    meaning: "errors visible, debuggable, traceable"
    detects: silent_errors
    severity: critical
    confidence: 0.95
    operation: fail_fast
  
  # Structure
  human_scale:
    meaning: "debuggable at 3am"
    detects: long_function
    severity: medium
    confidence: 0.90
    operation: extract
  
  clarity:
    meaning: "obvious intent"
    detects: unclear_naming
    severity: medium
    confidence: 0.70
    operation: rename
  
  simplicity:
    meaning: "remove until it hurts"
    detects: unused_code
    severity: low
    confidence: 0.90
    operation: delete
  
  consistency:
    meaning: "predictable patterns"
    detects: inconsistent_naming
    severity: low
    confidence: 0.85
    operation: standardize
  
  locality:
    meaning: "behavior near trigger"
    detects: action_at_distance
    severity: high
    confidence: 0.75
    operation: inline
  
  # System
  idempotency:
    meaning: "safely repeatable"
    detects: non_idempotent
    severity: high
    confidence: 0.75
    operation: add_idempotency
  
  extensibility:
    meaning: "open for extension"
    detects: modification_required
    severity: high
    confidence: 0.75
    operation: introduce_seam
  
  modularity:
    meaning: "depend on abstractions"
    detects: concrete_dependency
    severity: high
    confidence: 0.80
    operation: introduce_interface
  
  # Cognitive
  chunking:
    meaning: "7±2 items"
    detects: too_many_items
    severity: medium
    confidence: 0.80
    operation: categorize
  
  signal_noise:
    meaning: "maximize signal"
    detects: high_noise
    severity: medium
    confidence: 0.75
    operation: remove_cruft
  
  # Aesthetic
  negative_space:
    meaning: "breathing room"
    detects: visual_clutter
    severity: medium
    confidence: 0.70
    operation: add_whitespace
  
  hierarchy:
    meaning: "clear structure"
    detects: flat_hierarchy
    severity: medium
    confidence: 0.75
    operation: establish_hierarchy
  
  # Dynamics
  carrying_capacity:
    meaning: "respect limits"
    detects: over_capacity
    severity: critical
    confidence: 0.95
    operation: emergency_reduce
  
  # UX
  feedback:
    meaning: "visible state"
    detects: silent_operation
    severity: high
    confidence: 0.85
    operation: add_feedback
  
  sovereignty:
    meaning: "user controls, can undo"
    detects: unrecoverable_error
    severity: critical
    confidence: 0.95
    operation: add_recovery

smells:
  structural: [duplication, hidden_coupling, god_file, action_at_distance]
  naming: [unclear_naming, inconsistent_naming]
  complexity: [long_function, deep_nesting, too_many_items, high_complexity, high_noise]
  security: [unvalidated_input, privilege_escalation, plaintext_secrets]
  quality: [no_tests, unused_code, silent_errors]
  reliability: [non_idempotent, no_logging, silent_operation, over_capacity, unrecoverable_error]
  maintainability: [modification_required, concrete_dependency, no_maintenance]
  aesthetic: [visual_clutter, flat_hierarchy, over_polishing]

operations:
  # Simple (auto-apply)
  rename: "reveal intent"
  delete: "remove unused"
  standardize: "consistent format"
  add_whitespace: "breathing room"
  remove_cruft: "delete noise"
  
  # Medium
  extract: "to named function"
  flatten: "reduce nesting"
  add_guards: "validate input"
  add_tests: "coverage ≥80%"
  fail_fast: "visible failure"
  add_feedback: "show state"
  inline: "move behavior closer"
  categorize: "group into ≤7"
  establish_hierarchy: "clear structure"
  
  # Complex (require review)
  introduce_seam: "extension point"
  introduce_interface: "abstract dependency"
  add_idempotency: "safe retry"
  add_recovery: "undo mechanism"
  emergency_reduce: "immediate scope cut"

severity:
  critical: [no_tests, silent_errors, unvalidated_input, unrecoverable_error, over_capacity]
  high: [hidden_coupling, modification_required, non_idempotent, action_at_distance, silent_operation]
  medium: [unclear_naming, long_function, deep_nesting, too_many_items, flat_hierarchy]
  low: [unused_code, inconsistent_naming, visual_clutter, over_polishing]

fast_fail:
  unused_code: {test: "referenced?", no: delete}
  unvalidated_input: {test: "user-facing?", yes: add_guards}
  no_tests: {test: "production?", yes: add_tests}
  long_function: {test: "lines>20?", yes: extract}
  deep_nesting: {test: "depth>3?", yes: flatten}
  silent_errors: {test: "errors logged?", no: fail_fast}

languages:
  ruby:
    parser: ripper
    formatter: "rubocop --autocorrect"
    conventions: {naming: snake_case, indent: 2, line: 120}
    error_handling: "rescue with visible failures"
  
  javascript:
    parser: acorn
    formatter: "eslint --fix"
    conventions: {indent: 2, line: 100, semicolons: false}
    extract_function_at: 15
    constants_over_literals: true
    named_functions_preferred: true
  
  zsh:
    parser: "zsh -n"
    formatter: shfmt
    conventions: {strict: "set -euo pipefail", quoting: always}
  
  rust:
    parser: rust-analyzer
    formatter: rustfmt
    conventions: {indent: 4, line: 100}
  
  html_erb:
    formatter: prettier
    accessibility: [semantic_html, aria_labels, form_labels]
  
  css:
    formatter: prettier
    conventions: {indent: 2, naming: kebab-case}
  
  fallback:
    method: internal_heuristics
    confidence_penalty: 0.15

scanning:
  include:
    extensions: [.rb, .js, .mjs, .zsh, .sh, .rs, .html, .erb, .css, .scss]
    paths: ["app/**", "lib/**", "config/**", "spec/**", "test/**"]
  
  exclude:
    dirs: [node_modules, vendor, tmp, .git, dist, build, coverage]
    patterns: ["*.min.*", "*.map", "*.lock"]
    generated: [schema.rb, routes.rb, "*/migrations/*"]
  
  strategy:
    batch: 50
    checkpoint: ".master_checkpoint.json"
    resume: true

beautification:
  mode: deep_analysis_and_refactor
  principles: [human_scale, clarity, simplicity, consistency, negative_space, hierarchy, chunking]
  metrics: [readability, consistency, composition, cognitive_load]
  minimum_delta: 0.02
  anti_patterns: [over_polishing, forced_symmetry]
  
  process:
    phase_1_scan:
      - "read entire file into memory"
      - "parse AST if applicable"
      - "identify all functions, classes, blocks"
      - "measure: lines, complexity, nesting, duplication"
    
    phase_2_analyze:
      - "detect violations against all principles"
      - "calculate cognitive load per section"
      - "identify refactoring opportunities"
      - "assess naming clarity"
      - "find magic numbers/strings"
    
    phase_3_plan:
      - "rank violations by severity × confidence"
      - "generate 3-5 refactoring strategies"
      - "estimate semantic drift for each"
      - "select highest value, lowest risk"
    
    phase_4_refactor:
      - "extract long functions (>20 lines)"
      - "name all magic numbers as constants"
      - "eliminate duplication via extraction"
      - "improve naming for clarity"
      - "add whitespace for breathing room"
      - "organize: related code together"
    
    phase_5_verify:
      - "syntax check (language-specific)"
      - "measure semantic drift"
      - "recalculate metrics"
      - "confirm improvement > minimum_delta"
      - "rollback if drift > threshold"
    
    phase_6_iterate:
      - "repeat phases 2-5 until:"
      - "  violations == 0 OR"
      - "  improvement < minimum_delta OR"
      - "  cycles >= max_cycles"
  
  line_by_line_analysis:
    enabled: true
    for_each_line:
      - "check: line length <= threshold"
      - "check: indentation consistency"
      - "check: naming conventions"
      - "check: complexity (nested depth)"
      - "flag: magic numbers/strings"
      - "flag: duplication candidates"
    
  big_picture_analysis:
    enabled: true
    assess:
      - "file purpose clarity"
      - "module cohesion"
      - "dependency coupling"
      - "documentation adequacy"
      - "test coverage"
      - "error handling completeness"
    
  output:
    before_after_diff: true
    metrics_table: true
    violations_eliminated: true
    confidence_scores: true

gap_prevention:
  missing_operation:
    detection: "principle.operation not in operations"
    action: "flag as incomplete, suggest operation definition"
  
  orphan_smell:
    detection: "smell not detected by any principle"
    action: "flag for principle assignment"
  
  confidence_drift:
    detection: "prediction accuracy < 0.80 over 20 fixes"
    action: "recalibrate baselines"
  
  infinite_loop:
    detection: "same violation 3+ cycles"
    action: "halt, try alternative, escalate if fails"
  
  regression:
    detection: "violation count increased"
    action: "rollback, try conservative approach"

pitfall_prevention:
  data_loss: "checkpoint every batch"
  partial_apply: "atomic per-file, rollback on error"
  over_beautification: "score must improve"
  premature_stop: "require creative exhaustion before diminishing returns"
  silent_failure: "log all errors, never swallow exceptions"
  
  self_correction:
    on_any_error:
      - "log error with context"
      - "try alternative approach"
      - "if 3 failures, escalate to human"
    
    on_low_confidence:
      - "generate more alternatives"
      - "apply most conservative"
      - "flag for review"

output:
  style: "unix, terse, actionable"
  structure: "HH:MM:SS facility.priority: message"
  
  exit_codes:
    0: "clean or fixed"
    1: "violations need review"
    2: "usage error"
    3: "capability error"
    4: "drift exceeded"
    5: "regression"
    6: "veto"
    7: "center violation"
    8: "semantic drift"
    9: "calibration fail"
    10: "context exceeded"
  
  templates:
    violation: "{time} {facility}.{priority}: {principle} {smell} [{file}:{line}] ({op}) [c={conf}]"
    debug: "{time} debug.{severity}: {exception} [{file}:{line}] root={cause} fix={op}"
    status: "{time} {facility}.info: {message}"
    complete: "{time} converge.info: {fixed}/{total} violations, {cycles} cycles, next={action}"

interaction:
  on_start:
    - "acknowledge mode and task"
    - "estimate scope"
    - "begin immediately"
  
  during:
    - "progress every 50 files"
    - "alert on veto/drift immediately"
    - "auto-fix silently when confident"
  
  on_complete:
    - "summary: violations fixed, cycles, metrics"
    - "concrete next steps if any remain"
    - "no explanatory prose"
  
  style:
    tone: "direct, technical"
    format: "terse, bullets if multiple items"
    focus: "what to do, not why"

self_test:
  on: activation
  checks:
    - "all principles have operations"
    - "all operations exist"
    - "all smells in taxonomy"
    - "confidence bounds valid"
    - "no circular references"

self_healing:
  trigger: "on_load OR weekly"
  state_store: ".master_checkpoint.json"
  check: "current_time - state_store.meta.last_self_heal > 7 days"
  process: "optimized_loop on self"
  auto_fix: true
  on_complete: "update state_store.meta.last_self_heal = current_time"

scanning:
  checkpoint:
    file: ".master_checkpoint.json"
    schema:
      meta:
        last_self_heal: "ISO8601 timestamp"
        version: "master.yml version"
      progress:
        last_file: "path"
        batch_count: "integer"
        violations_found: "integer"
    persistence: "json format, atomic writes"

tooling:
  banned: [bash, powershell, sed, awk, python, sudo]
  preferred: {shell: zsh, analysis: ruby}
  external: [rubocop, prettier, eslint, rustfmt, shfmt]
  
  ssh_automation:
    method: "Ruby Net::SSH gem"
    library: net-ssh
    install: "gem install net-ssh --no-document"
    usage: |
      require 'net/ssh'
      Net::SSH.start(host, user, password: pwd, verify_host_key: :never) do |ssh|
        output = ssh.exec!('command')
        # For long-running commands, use channels for incremental output
        ssh.open_channel do |ch|
          ch.exec('long_command') do |ch, success|
            ch.on_data { |c, data| puts data }
          end
        end
        ssh.loop
      end
    example_deployment: |
      Net::SSH.start('185.52.176.18', 'dev', password: 'hutte10tu6969', verify_host_key: :never) do |ssh|
        ssh.scp.upload!('file.sh', '/home/dev/file.sh')
        ssh.exec!('doas zsh ~/file.sh')
      end
    transparency: "Always output progress, never run silent for >60 seconds"

glossary:
  center: "core purpose all changes preserve"
  veto: "absolute block by security/maintainer"
  blast_radius: "scope of change impact"
  ewma: "exponentially weighted moving average"
  semantic_drift: "AST-level behavioral change"
  autonomous: "act without asking when confident"