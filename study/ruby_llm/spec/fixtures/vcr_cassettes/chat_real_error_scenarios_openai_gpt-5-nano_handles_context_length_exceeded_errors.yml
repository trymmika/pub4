---
http_interactions:
- request:
    method: post
    uri: https://api.openai.com/v1/chat/completions
    body:
      encoding: UTF-8
      string: '{"model":"gpt-5-nano","messages":[{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"<MASSIVE_TEXT>"},{"role":"assistant","content":"<MASSIVE_TEXT>"},{"role":"user","content":"Hi"}],"stream":false}'
    headers:
      User-Agent:
      - Faraday v2.14.1
      Authorization:
      - Bearer <OPENAI_API_KEY>
      Content-Type:
      - application/json
      Accept-Encoding:
      - gzip;q=1.0,deflate;q=0.6,identity;q=0.3
      Accept:
      - "*/*"
  response:
    status:
      code: 429
      message: Too Many Requests
    headers:
      Date:
      - Tue, 10 Feb 2026 08:57:09 GMT
      Content-Type:
      - application/json; charset=utf-8
      Content-Length:
      - '412'
      Connection:
      - keep-alive
      Vary:
      - Origin
      X-Ratelimit-Limit-Requests:
      - '500'
      X-Ratelimit-Limit-Tokens:
      - '200000'
      X-Ratelimit-Remaining-Requests:
      - '499'
      X-Ratelimit-Remaining-Tokens:
      - '200000'
      X-Ratelimit-Reset-Requests:
      - 120ms
      X-Ratelimit-Reset-Tokens:
      - 0s
      X-Request-Id:
      - "<X_REQUEST_ID>"
      X-Openai-Proxy-Wasm:
      - v0.1
      Server:
      - cloudflare
      Cf-Cache-Status:
      - DYNAMIC
      Set-Cookie:
      - "<COOKIE>"
      - "<COOKIE>"
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      X-Content-Type-Options:
      - nosniff
      Cf-Ray:
      - "<CF_RAY>"
      Alt-Svc:
      - h3=":443"; ma=86400
    body:
      encoding: UTF-8
      string: |
        {
            "error": {
                "message": "Request too large for gpt-5-nano in organization org-eLwBCUaB2ePnSi6dlToWtHZK on tokens per min (TPM): Limit 200000, Requested 2500013. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.",
                "type": "tokens",
                "param": null,
                "code": "rate_limit_exceeded"
            }
        }
  recorded_at: Sat, 14 Feb 2026 10:11:31 GMT
recorded_with: VCR 6.4.0
